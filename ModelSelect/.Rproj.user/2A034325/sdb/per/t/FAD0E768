{
    "contents" : "modelSelect <- function(dat, folds,nnetSize, numPreds) {\n  require(nnet)\n  #Preprocess---------------------------------------------------------------------------------------------------\n  allModelErrors <<- rep(0, numPreds)\n  allModelFormulas = list()\n  length(allModelFormulas) = numPreds\n  names(dat)[2] = \"DIAGNOSIS\"\n#   dat$DIAGNOSIS = gsub('PD',1,dat$DIAGNOSIS)\n#   dat$DIAGNOSIS = gsub('HC',0,dat$DIAGNOSIS)\n  remainingPreds= names(dat)[3:(length(names(dat))-6)]\n  basePreds <<- c(\"CAUDATE_R\", \"CAUDATE_L\", \"PUTAMEN_R\", \"PUTAMEN_L\", \"CAUDATE_ASYMMETRY\", \"PUTAMEN_ASYMMETRY\")\n  \n  #split data into test and kfold\n  testInd = sample(1:dim(dat)[1],floor(.25*dim(dat)[1]))\n  testdata = dat[testInd,]\n  Kfolddata = dat[-testInd,]\n  \n  #KFold Cross-Validation---------------------------------------------------------------------------------------------------\n  for (p in 1:numPreds) {\n    errorList = rep(0,length(remainingPreds))\n    list = 1:folds\n    id = sample(1:folds,nrow(Kfolddata),replace = TRUE)\n    for (i in 1:folds) {\n      trainSet = subset(dat, id %in% list[-i])\n      testSet = subset(dat, id %in% c(i))\n      print(paste('Fold: ',i))\n      for (m in 1:length(remainingPreds)) {\n        print(m)\n        modelNNet = nnet(as.formula(paste(paste(\"DIAGNOSIS~\",paste(basePreds,collapse=\"+\")),'+',remainingPreds[m])) ,\n                         data = trainSet, size = nnetSize, rang = 0.4, decay = 5e-4, maxit = 300, trace = FALSE)\n        modelPred = predict(object = modelNNet, newdata = testSet, type = 'raw')\n        modelPred = round(modelPred, digits = 0)\n        classTable = table(testSet$DIAGNOSIS, modelPred)\n        errorList[m] = errorList[m] + (1-sum(diag(classTable))/sum(classTable))\n      }\n    }\n    errorList = errorList / folds\n    \n    \n    #find model with min error and add predictor to current model\n    minIndex = match(min(errorList),errorList)\n    predToAdd = remainingPreds[minIndex]\n    remainingPreds = remainingPreds[-minIndex]\n    basePreds <<- c(basePreds, predToAdd)\n    print(basePreds)\n    print(paste(\"Current model error rate: \",errorList[minIndex]))\n    allModelErrors[p] <<- errorList[minIndex]\n    allModelFormulas[[p]] <<- as.formula(paste(\"DIAGNOSIS~\",paste(basePreds,collapse=\"+\")))\n    \n    modelNNet = nnet(as.formula(paste(paste(\"DIAGNOSIS~\",paste(basePreds,collapse=\"+\")),'+',predToAdd)) ,\n                     data = trainSet, size = nnetSize, rang = 0.4, decay = 5e-4, maxit = 300, trace = FALSE)\n    modelPred = predict(object = modelNNet, newdata = testSet, type = 'raw')\n    modelPred = round(modelPred, digits = 0)\n    pred <- prediction(modelPred, testSet$DIAGNOSIS)\n    perf <- performance(pred, measure = \"tpr\", x.measure = \"fpr\") \n    plot(perf, col=rainbow(10))\n  }\n  \n  minIndex = match(min(allModelErrors),allModelErrors)\n  modelToUse = allModelFormulas[minIndex]\n\n  modelNNet = nnet(modelToUse, data = testdata, size = nnetSize, rang = 0.4, decay = 5e-4, maxit = 300, trace = FALSE)\n  modelPred = predict(object = modelNNet, newdata = testdata, type = 'raw')\n  modelPred = round(modelPred, digits = 0)\n  classTable = table(testdata$DIAGNOSIS, modelPred)\n  print(paste(\"FINAL ERROR RATE: \", (1-sum(diag(classTable))/sum(classTable))))\n}",
    "created" : 1399423090456.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "4065196534",
    "id" : "FAD0E768",
    "lastKnownWriteTime" : 1399138843,
    "path" : "~/Cornell/Senior Year/Spring 2014/ORIE 4740/ORIE4740_data/ModelSelect/modelSelect.R",
    "project_path" : "modelSelect.R",
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_source"
}